import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è¡Œäº‹æ›†åˆ†æåŠ©ç†", page_icon="ğŸ“…")
st.title("ğŸ“… æ™ºèƒ½è¡Œäº‹æ›†åˆ†æåŠ©ç†")

# --- è¨ºæ–·è¨Šæ¯ (é™¤éŒ¯ç”¨) ---
# é€™è¡Œæœƒé¡¯ç¤ºåœ¨ç¶²é æœ€ä¸Šæ–¹ï¼Œç¢ºèª SDK ç‰ˆæœ¬æ˜¯å¦æ­£ç¢º
st.caption(f"ç³»çµ±è¨ºæ–·ï¼šGoogle GenAI SDK ç‰ˆæœ¬: {genai.__version__}")

if genai.__version__ < "0.7.0":
    st.error("âš ï¸ ç³»çµ±åµæ¸¬åˆ°ç‰ˆæœ¬éèˆŠï¼è«‹ä¿®æ”¹ requirements.txt ç‚º google-generativeai==0.8.3 ä¸¦é¸æ“‡ 'Reboot app'ã€‚")
    st.stop()

# --- è‡ªå‹•è®€å– API Key ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception:
    st.error("âš ï¸ æœªåµæ¸¬åˆ° API Keyã€‚è«‹è‡³ Streamlit Settings -> Secrets è¨­å®šã€‚")
    st.stop()

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ“¸ ä¸Šå‚³è¡Œäº‹æ›†")
    uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ç…§ç‰‡ (jpg, png)", type=["jpg", "jpeg", "png"])
    
    image = None
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="é è¦½", use_column_width=True)
        st.success("åœ–ç‰‡è®€å–æˆåŠŸï¼")

# --- åˆå§‹åŒ–å°è©± ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯è¡Œäº‹æ›†åŠ©ç† (ä½¿ç”¨ Gemini 1.5 Flash æ¨¡å‹)ã€‚è«‹ä¸Šå‚³ç…§ç‰‡æˆ–è¼¸å…¥æ–‡å­—ã€‚"}
    ]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# --- ä¸»è¦é‚è¼¯ ---
if prompt := st.chat_input("è¼¸å…¥æŒ‡ä»¤..."):
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # æº–å‚™è¼¸å…¥
    content_input = [prompt]
    if image:
        content_input.append(image)
        content_input.insert(0, "è«‹åˆ†æé€™å¼µè¡Œäº‹æ›†åœ–ç‰‡ï¼Œåˆ—å‡ºæ—¥æœŸã€æ™‚é–“èˆ‡äº‹ä»¶ã€‚")

    # å‘¼å« AI
    try:
        # åªä½¿ç”¨æœ€æ–°çš„ 1.5 Flashï¼Œä¸å†é€€å›èˆŠç‰ˆ
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        with st.chat_message("assistant"):
            response = model.generate_content(content_input, stream=True)
            full_response = ""
            placeholder = st.empty()
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    placeholder.markdown(full_response + "â–Œ")
            placeholder.markdown(full_response)
            
        st.session_state.messages.append({"role": "assistant", "content": full_response})

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        st.info("å¦‚æœæŒçºŒå ±éŒ¯ 404ï¼Œè«‹æª¢æŸ¥æ‚¨çš„ API Key æ˜¯å¦æ­£ç¢ºï¼Œæˆ–è©² Key æ˜¯å¦æœ‰å•Ÿç”¨ Generative AI API æ¬Šé™ã€‚")
