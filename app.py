import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è¡Œäº‹æ›†åˆ†æåŠ©ç†", page_icon="ğŸ“…")
st.title("ğŸ“… æ™ºèƒ½è¡Œäº‹æ›†åˆ†æåŠ©ç†")
st.caption("ä¸Šå‚³è¡Œäº‹æ›†æˆªåœ–æˆ–ç…§ç‰‡ï¼ŒAI å¹«æ‚¨åˆ†æè¡Œç¨‹ | ä¾›å…§éƒ¨ä½¿ç”¨")

# --- è‡ªå‹•è®€å– API Key (å¾ Secrets) ---
# é€™è£¡æœƒè‡ªå‹•æŠ“å–æ‚¨åœ¨ Streamlit å¾Œå°è¨­å®šçš„ Keyï¼ŒåŒäº‹ä¸éœ€è¦è¼¸å…¥
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception:
    st.error("âš ï¸ æœªåµæ¸¬åˆ° API Keyã€‚è«‹ç®¡ç†è€…è‡³ Streamlit å¾Œå° Settings -> Secrets è¨­å®š GOOGLE_API_KEYã€‚")
    st.stop()

# --- å´é‚Šæ¬„ï¼šåœ–ç‰‡ä¸Šå‚³å€ ---
with st.sidebar:
    st.header("ğŸ“¸ ä¸Šå‚³è¡Œäº‹æ›†")
    uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ç…§ç‰‡æˆ–æˆªåœ– (jpg, png)", type=["jpg", "jpeg", "png"])
    
    image_prompt = ""
    if uploaded_file is not None:
        # é¡¯ç¤ºé è¦½åœ–
        image = Image.open(uploaded_file)
        st.image(image, caption="å·²ä¸Šå‚³çš„è¡Œäº‹æ›†", use_column_width=True)
        st.success("åœ–ç‰‡è®€å–æˆåŠŸï¼ç¾åœ¨å¯ä»¥åœ¨å³å´å°è©±æ¡†è¦æ±‚ AI åˆ†æé€™å¼µåœ–ã€‚")
    else:
        st.info("ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥æˆªåœ– Google Calendar æˆ–æ‹ä¸‹ç´™æœ¬è¡Œäº‹æ›†ä¸Šå‚³ã€‚")

# --- åˆå§‹åŒ–å°è©±ç´€éŒ„ ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "model", "content": "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„è¡Œäº‹æ›†åŠ©ç†ã€‚è«‹ä¸Šå‚³è¡Œäº‹æ›†ç…§ç‰‡ï¼Œæˆ–è€…ç›´æ¥è²¼ä¸Šè¡Œç¨‹æ–‡å­—ï¼Œæˆ‘æœƒå¹«ä½ æ•´ç†ä¸¦æª¢æŸ¥è¡çªã€‚"}
    ]

# --- é¡¯ç¤ºæ­·å²è¨Šæ¯ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- è™•ç†ä½¿ç”¨è€…è¼¸å…¥ ---
if prompt := st.chat_input("è¼¸å…¥æŒ‡ä»¤... (ä¾‹å¦‚ï¼šå¹«æˆ‘åˆ†æé€™é€±è¡Œç¨‹æœ‰ä»€éº¼è¡çªï¼Ÿ)"):
    
    # é¡¯ç¤ºä½¿ç”¨è€…æ–‡å­—
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # å‘¼å« AI
    try:
        model = genai.GenerativeModel('gemini-1.5-pro')
        
        # æº–å‚™ç™¼é€çµ¦ AI çš„å…§å®¹
        # å¦‚æœæœ‰ä¸Šå‚³åœ–ç‰‡ï¼Œå°±æŠŠåœ–ç‰‡è·Ÿæ–‡å­—ä¸€èµ·é€å‡ºå»
        if uploaded_file:
            inputs = [prompt, image]
        else:
            inputs = [prompt]

        # åŠ ä¸Šç³»çµ±æç¤º (System Instruction) è®“ AI æ›´è°æ˜
        system_prompt = "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­ç§˜æ›¸ã€‚è«‹åˆ†æä½¿ç”¨è€…çš„è¼¸å…¥ï¼ˆå¯èƒ½æ˜¯æ–‡å­—æˆ–è¡Œäº‹æ›†åœ–ç‰‡ï¼‰ã€‚å¦‚æœæ˜¯åœ–ç‰‡ï¼Œè«‹ä»”ç´°è¾¨è­˜ä¸Šé¢çš„æ—¥æœŸèˆ‡æ™‚é–“ã€‚è«‹åˆ—å‡ºè¡Œç¨‹æ¸…å–®ï¼Œä¸¦æª¢æŸ¥æ˜¯å¦æœ‰æ™‚é–“è¡çªã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"
        
        # é€™è£¡æˆ‘å€‘æŠŠç³»çµ±æç¤ºåŠ åœ¨ inputs æœ€å‰é¢
        inputs.insert(0, system_prompt)

        with st.chat_message("model"):
            message_placeholder = st.empty()
            
            # ä½¿ç”¨ generate_content è™•ç†å–®æ¬¡è«‹æ±‚ï¼ˆåŒ…å«åœ–ç‰‡ï¼‰
            # è¨»ï¼šç‚ºäº†ç°¡åŒ–åœ–ç‰‡è™•ç†é‚è¼¯ï¼Œé€™å€‹ç‰ˆæœ¬ä¸»è¦é‡å°ç•¶ä¸‹ä¸Šå‚³çš„åœ–ç‰‡é€²è¡Œåˆ†æ
            response = model.generate_content(inputs, stream=True)
            
            full_response = ""
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
            
        st.session_state.messages.append({"role": "model", "content": full_response})

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ï¼š{e}")
