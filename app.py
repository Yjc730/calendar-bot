import streamlit as st
import google.generativeai as genai

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è¡Œäº‹æ›†åˆ†æåŠ©ç†", page_icon="ğŸ“…")
st.title("ğŸ“… æ™ºèƒ½è¡Œäº‹æ›†åˆ†æåŠ©ç†")
st.caption("ç”± Google Gemini é©…å‹• | å…è²»ç‰ˆ")

# --- å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    # è®“ä½¿ç”¨è€…åœ¨ä»‹é¢ä¸Šè¼¸å…¥ API Keyï¼Œé€™æ¨£ä½ ä¸ç”¨æŠŠ Key å¯«æ­»åœ¨ç¨‹å¼ç¢¼è£¡ï¼Œæ¯”è¼ƒå®‰å…¨
    api_key = st.text_input("è«‹è¼¸å…¥ Google API Key", type="password")
    st.markdown("[ğŸ‘‰ æŒ‰æ­¤å…è²»å–å¾— API Key](https://aistudio.google.com/app/apikey)")
    st.divider()
    st.info("ğŸ’¡ èªªæ˜ï¼šè«‹åœ¨å³å´å°è©±æ¡†è²¼ä¸Šæ‚¨çš„è¡Œç¨‹ï¼ŒAI æœƒå¹«æ‚¨åˆ†ææ™‚é–“è¡çªæˆ–çµ¦äºˆå»ºè­°ã€‚")

# --- åˆå§‹åŒ–å°è©±ç´€éŒ„ ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "model", "content": "ä½ å¥½ï¼è«‹è²¼ä¸Šä½ çš„è¡Œç¨‹æ–‡å­—ï¼ˆä¾‹å¦‚ï¼šé€±ä¸€ 10:00 é–‹æœƒ...ï¼‰ï¼Œæˆ‘æœƒå¹«ä½ æ•´ç†ä¸¦æª¢æŸ¥æ˜¯å¦æœ‰æ™‚é–“è¡çªã€‚"}
    ]

# --- é¡¯ç¤ºæ­·å²è¨Šæ¯ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- è™•ç†ä½¿ç”¨è€…è¼¸å…¥ ---
if prompt := st.chat_input("è¼¸å…¥è¡Œç¨‹å®‰æ’..."):
    # æª¢æŸ¥æœ‰æ²’æœ‰è¼¸å…¥ API Key
    if not api_key:
        st.error("è«‹å…ˆåœ¨å·¦å´æ¬„ä½è¼¸å…¥ API Key æ‰èƒ½é‹ä½œå–”ï¼")
        st.stop()

    # é¡¯ç¤ºä½¿ç”¨è€…è¼¸å…¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # å‘¼å« AI
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # ç³»çµ±æç¤ºè©ï¼šè¨­å®š AI çš„äººè¨­
        system_prompt = """
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç§˜æ›¸èˆ‡æ™‚é–“ç®¡ç†å°ˆå®¶ã€‚è«‹é‡å°ä½¿ç”¨è€…çš„è¡Œç¨‹æ–‡å­—é€²è¡Œåˆ†æï¼š
        1. **æ•´ç†è¡Œç¨‹**ï¼šåˆ—å‡ºæ¸…æ™°çš„æ™‚é–“è¡¨ã€‚
        2. **åµæ¸¬è¡çª**ï¼šå¦‚æœæœ‰æ™‚é–“é‡ç–Šï¼Œè«‹å‹™å¿…ç”¨ç²—é«”è­¦å‘Šã€‚
        3. **èªæ°£**ï¼šä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œè¦ªåˆ‡ä¸”å°ˆæ¥­ã€‚
        """
        
        # çµ„åˆæ­·å²å°è©±çµ¦ AI
        history_for_ai = []
        for msg in st.session_state.messages:
            if msg["role"] == "user":
                history_for_ai.append({"role": "user", "parts": [msg["content"]]})
            else:
                history_for_ai.append({"role": "model", "parts": [msg["content"]]})
        
        # ç™¼é€è«‹æ±‚
        with st.chat_message("model"):
            message_placeholder = st.empty()
            # ç‚ºäº†ç°¡åŒ–ï¼Œé€™è£¡æˆ‘å€‘ç›´æ¥æŠŠ system prompt åŠ åœ¨æœ€å¾Œä¸€æ¬¡çš„è¼¸å…¥å‰
            full_prompt = system_prompt + "\n\nä½¿ç”¨è€…è¼¸å…¥ï¼š" + prompt
            
            response = model.generate_content(history_for_ai[:-1] + [{'role':'user', 'parts':[full_prompt]}], stream=True)
            
            full_response = ""
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
            
        st.session_state.messages.append({"role": "model", "content": full_response})

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}ã€‚è«‹æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢ºã€‚")
